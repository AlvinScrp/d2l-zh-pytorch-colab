{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22246426",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-20T01:46:03.658650Z",
     "iopub.status.busy": "2025-09-20T01:46:03.658339Z",
     "iopub.status.idle": "2025-09-20T01:46:05.073737Z",
     "shell.execute_reply": "2025-09-20T01:46:05.073284Z",
     "shell.execute_reply.started": "2025-09-20T01:46:03.658635Z"
    },
    "id": "22246426",
    "outputId": "26f78adb-4882-4816-aa50-ba453c5496b9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting d2l\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8b/39/418ef003ed7ec0f2a071e24ec3f58c7b1f179ef44bec5224dcca276876e3/d2l-1.0.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: d2l\n",
      "Successfully installed d2l-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy d2l --no-deps # installing d2l # installing d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66ef1699-7ef8-4fd6-ae44-65847ca987a5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-09-20T06:20:21.733375Z",
     "iopub.status.busy": "2025-09-20T06:20:21.733001Z",
     "iopub.status.idle": "2025-09-20T06:27:21.636395Z",
     "shell.execute_reply": "2025-09-20T06:27:21.635650Z",
     "shell.execute_reply.started": "2025-09-20T06:20:21.733355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 1.802397, train acc 0.591, test acc 0.780 | LR: 0.000225 | best_test_acc:0.780\n",
      "epoch 2 loss 0.422843, train acc 0.892, test acc 0.894 | LR: 0.000169 | best_test_acc:0.894\n",
      "epoch 3 loss 0.154660, train acc 0.962, test acc 0.938 | LR: 0.000127 | best_test_acc:0.938\n",
      "epoch 4 loss 0.070463, train acc 0.982, test acc 0.947 | LR: 0.000095 | best_test_acc:0.947\n",
      "epoch 5 loss 0.042079, train acc 0.989, test acc 0.957 | LR: 0.000071 | best_test_acc:0.957\n",
      "epoch 6 loss 0.026781, train acc 0.991, test acc 0.957 | LR: 0.000053 | best_test_acc:0.957\n",
      "epoch 7 loss 0.023295, train acc 0.991, test acc 0.960 | LR: 0.000040 | best_test_acc:0.960\n",
      "epoch 8 loss 0.019853, train acc 0.992, test acc 0.961 | LR: 0.000030 | best_test_acc:0.961\n",
      "epoch 9 loss 0.018772, train acc 0.992, test acc 0.965 | LR: 0.000023 | best_test_acc:0.965\n",
      "epoch 10 loss 0.017576, train acc 0.992, test acc 0.966 | LR: 0.000017 | best_test_acc:0.966\n",
      "epoch 11 loss 0.016503, train acc 0.993, test acc 0.960 | LR: 0.000013 | best_test_acc:0.966\n",
      "epoch 12 loss 0.015995, train acc 0.992, test acc 0.963 | LR: 0.000010 | best_test_acc:0.966\n",
      "epoch 13 loss 0.015407, train acc 0.993, test acc 0.962 | LR: 0.000007 | best_test_acc:0.966\n",
      "epoch 14 loss 0.014909, train acc 0.994, test acc 0.960 | LR: 0.000005 | best_test_acc:0.966\n",
      "epoch 15 loss 0.014746, train acc 0.993, test acc 0.962 | LR: 0.000004 | best_test_acc:0.966\n",
      "epoch 16 loss 0.014452, train acc 0.992, test acc 0.965 | LR: 0.000003 | best_test_acc:0.966\n",
      "epoch 17 loss 0.014059, train acc 0.994, test acc 0.962 | LR: 0.000002 | best_test_acc:0.966\n",
      "epoch 18 loss 0.013984, train acc 0.993, test acc 0.959 | LR: 0.000002 | best_test_acc:0.966\n",
      "epoch 19 loss 0.013472, train acc 0.994, test acc 0.962 | LR: 0.000001 | best_test_acc:0.966\n",
      "epoch 20 loss 0.013437, train acc 0.993, test acc 0.961 | LR: 0.000001 | best_test_acc:0.966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 205\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# ======================\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# 5. 训练\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# ======================\u001b[39;00m\n\u001b[32m    203\u001b[39m lr, num_epochs,weight_decay = \u001b[32m0.0003\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m1e-4\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md2l\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtry_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mtrain_ch6\u001b[39m\u001b[34m(net, train_iter, test_iter, num_epochs, lr, weight_decay, device)\u001b[39m\n\u001b[32m    173\u001b[39m y_hat = net(X)\n\u001b[32m    174\u001b[39m l = loss(y_hat, y)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m optimizer.step()\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    517\u001b[39m         Tensor.backward,\n\u001b[32m    518\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         inputs=inputs,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    262\u001b[39m     retain_graph = create_graph\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts,ExponentialLR,ReduceLROnPlateau\n",
    "\n",
    "# ======================\n",
    "# 1. 自定义 Dataset\n",
    "# ======================\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir=\"\", transform=None,class_to_idx=None, is_train=False):\n",
    "        \"\"\"\n",
    "        csv_file: csv 文件路径\n",
    "        img_dir: 图片所在目录（可为空，如果 csv 里 image 列已经有完整路径）\n",
    "        transform: torchvision.transforms\n",
    "        is_test: 是否是测试集（没有 label）\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df.columns = self.df.columns.str.strip()  # 去掉列名空格\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "        # 如果是训练集，构建标签映射\n",
    "        if is_train and \"label\" in self.df.columns:\n",
    "            self.classes = sorted(class_to_idx.keys())\n",
    "            self.df['label_idx'] = self.df['label'].map(self.class_to_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image']) if self.img_dir else row['image']\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.is_train or \"label_idx\" not in self.df.columns:\n",
    "            return img, -1   # 测试集没有标签，用 -1 占位\n",
    "        else:\n",
    "            return img, row['label_idx']\n",
    "\n",
    "\n",
    "def split_train_val(dataset: Dataset, val_ratio=0.25):\n",
    "    \"\"\"\n",
    "    按比例拆分训练集和验证集\n",
    "    \"\"\"\n",
    "    n_total = len(dataset)\n",
    "    indices = list(range(n_total))\n",
    "    random.shuffle(indices)  # <-- 关键！打乱索引\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_idx = indices[:n_train]\n",
    "    val_idx = indices[n_train:]\n",
    "\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    return train_subset, val_subset\n",
    "\n",
    "# ======================\n",
    "# 2. Transform\n",
    "# ======================\n",
    "def get_transforms(is_train=True, img_size=224):\n",
    "    \"\"\"获取图片预处理变换\"\"\"\n",
    "    if is_train:\n",
    "        # 训练集数据增强\n",
    "        # 方案二：更温和的数据增强\n",
    "        # return transforms.Compose([\n",
    "        #     # 直接将图片缩放到目标尺寸\n",
    "        #     transforms.Resize((img_size, img_size)), \n",
    "        #     # 只进行水平翻转\n",
    "        #     transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #     # (可选) 可以加上轻微的旋转\n",
    "        #     # transforms.RandomRotation(10), \n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                          std=[0.229, 0.224, 0.225])\n",
    "        # ])\n",
    "        # 训练集数据增强\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((256, 256)),  # 先resize到稍大尺寸\n",
    "            transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),  # 随机裁剪\n",
    "            transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "            transforms.RandomVerticalFlip(p=0.3),    # 随机垂直翻转\n",
    "            transforms.RandomRotation(15),  # 随机旋转\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 颜色抖动\n",
    "            transforms.ToTensor(),  # 转换为张量，自动归一化到[0,1]\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],   # ImageNet标准化\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        # 验证/测试集\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# ======================\n",
    "# 3. 创建 Dataset & DataLoader\n",
    "# ======================\n",
    "batch_size = 32\n",
    "\n",
    "# transform\n",
    "train_tf = get_transforms(is_train=True)\n",
    "eval_tf  = get_transforms(is_train=False)\n",
    "\n",
    "# 全局生成 class_to_idx\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df['label'] = df['label'].astype(str).str.strip()\n",
    "classes = sorted(df['label'].unique())\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "\n",
    "\n",
    "# 读取完整数据集（先传入 train_tf，后面拆分验证集时再换 transform）\n",
    "full_dataset = ImageDataset(\"train.csv\", transform=train_tf,class_to_idx=class_to_idx, is_train=True)\n",
    "\n",
    "# 拆分训练集和验证集\n",
    "train_dataset, val_dataset = split_train_val(full_dataset, val_ratio=0.1)\n",
    "\n",
    "# 注意：val_dataset 是 Subset，要替换成 eval_tf\n",
    "val_dataset.dataset.transform = eval_tf\n",
    "\n",
    "# DataLoader\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_iter   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ======================\n",
    "# 4. 定义网络（用 ResNet18）\n",
    "# ======================\n",
    "import torchvision\n",
    "net = torchvision.models.resnet18(pretrained=True)\n",
    "num_classes = len(full_dataset.classes)\n",
    "net.fc = nn.Sequential(\n",
    "    # nn.Dropout(0.2),\n",
    "    nn.Linear(net.fc.in_features, num_classes)\n",
    ")\n",
    "\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr,weight_decay, device):\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    best_test_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    early_stopping_round = 11\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.80,verbose=True)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, mode='min',factor=0.4,patience=1,threshold=0.1, verbose=True,min_lr=1e-6)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20,eta_min=1e-6)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            # if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "            #     animator.add(epoch + (i + 1) / num_batches,\n",
    "            #                  (train_l, train_acc, None))\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_epoch = epoch\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "            # print(f'==> New best model saved with Val Acc: {best_test_acc:.4f}')\n",
    "        if epoch - best_epoch >= early_stopping_round:\n",
    "            break\n",
    "        # animator.add(epoch + 1, (None, None, test_acc))\n",
    "        # scheduler.step(train_l)\n",
    "        scheduler.step()\n",
    "        print(f'epoch {epoch+1} loss {train_l:.6f}, train acc {train_acc:.3f}, ' f'test acc {test_acc:.3f} | LR: {scheduler.get_last_lr()[0]:.6f} | best_test_acc:{best_test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')\n",
    "\n",
    "# ======================\n",
    "# 5. 训练\n",
    "# ======================\n",
    "lr, num_epochs,weight_decay = 0.0003, 30, 1e-4\n",
    "\n",
    "train_ch6(net, train_iter, val_iter, num_epochs, lr,weight_decay, d2l.try_gpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf404f7f-b244-4617-a6e4-6bef2bdcfbc4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-09-20T06:18:50.508322Z",
     "iopub.status.busy": "2025-09-20T06:18:50.507998Z",
     "iopub.status.idle": "2025-09-20T06:18:59.001042Z",
     "shell.execute_reply": "2025-09-20T06:18:59.000422Z",
     "shell.execute_reply.started": "2025-09-20T06:18:50.508300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接使用当前模型，准备对测试集进行预测...\n",
      "预测完成！\n",
      "last_submission.csv 文件已成功生成！\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 6. (方案B) 直接使用内存中的 net 对象进行预测\n",
    "# =======================================================\n",
    "\n",
    "# 假设你刚刚运行完训练循环，`net` 对象还在内存中\n",
    "device=d2l.try_gpu()\n",
    "import torchvision\n",
    "net = torchvision.models.resnet18(pretrained=True)\n",
    "num_classes = len(full_dataset.classes)\n",
    "net.fc = nn.Sequential(\n",
    "    # nn.Dropout(0.2),\n",
    "    nn.Linear(net.fc.in_features, num_classes)\n",
    ")\n",
    "net.load_state_dict(torch.load('best_model.pth',map_location=device))\n",
    "net.to(device)\n",
    "# --- 1. 准备工作 ---\n",
    "# 关键！将模型切换到评估模式\n",
    "net.eval() \n",
    "\n",
    "print(\"直接使用当前模型，准备对测试集进行预测...\")\n",
    "# 测试集（用相同的 eval_tf）\n",
    "test_dataset = ImageDataset(\"test.csv\", transform=eval_tf,class_to_idx=class_to_idx, is_train=False)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- 2. 执行预测 ---\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X, _ in test_iter:\n",
    "        X = X.to( device) # 确保测试数据也移动到GPU\n",
    "        outputs = net(X)\n",
    "        predicted_indices = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(predicted_indices.cpu().numpy())\n",
    "\n",
    "print(\"预测完成！\")\n",
    "\n",
    "# --- 3. 转换预测结果 ---\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "pred_labels = [idx_to_class[i] for i in all_preds]\n",
    "\n",
    "# --- 4. 生成提交文件 ---\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "submission_df = pd.DataFrame({\n",
    "    'image': test_df['image'],\n",
    "    'label': pred_labels\n",
    "})\n",
    "submission_df.to_csv('last_submission.csv', index=False)\n",
    "\n",
    "print(\"last_submission.csv 文件已成功生成！\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
