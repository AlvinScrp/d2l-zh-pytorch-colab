{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0b746c-fc88-41f8-8acd-fbd84fd5798e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct  5 13:27:39 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 12.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:00:08.0 Off |                  Off |\n",
      "| N/A   28C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True,\n",
    "   text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98e4b84-3e49-407a-ab6d-48aaa3ef6802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.13.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp311-cp311-linux_x86_64.whl (1977.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m  \u001b[33m0:02:45\u001b[0m6m0:00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1+cu116 (from versions: 0.1.6, 0.2.0, 0.15.0+cpu, 0.15.0+cu117, 0.15.0+cu118, 0.15.1, 0.15.1+cpu, 0.15.1+cu117, 0.15.1+cu118, 0.15.2, 0.15.2+cpu, 0.15.2+cu117, 0.15.2+cu118, 0.15.2+rocm5.3, 0.15.2+rocm5.4.2, 0.16.0, 0.16.0+cpu, 0.16.0+cu118, 0.16.0+cu121, 0.16.0+rocm5.5, 0.16.0+rocm5.6, 0.16.1, 0.16.1+cpu, 0.16.1+cu118, 0.16.1+cu121, 0.16.1+rocm5.5, 0.16.1+rocm5.6, 0.16.2, 0.16.2+cpu, 0.16.2+cu118, 0.16.2+cu121, 0.16.2+rocm5.5, 0.16.2+rocm5.6, 0.17.0, 0.17.0+cpu, 0.17.0+cu118, 0.17.0+cu121, 0.17.0+rocm5.6, 0.17.0+rocm5.7, 0.17.1, 0.17.1+cpu, 0.17.1+cu118, 0.17.1+cu121, 0.17.1+rocm5.6, 0.17.1+rocm5.7, 0.17.2, 0.17.2+cpu, 0.17.2+cu118, 0.17.2+cu121, 0.17.2+rocm5.6, 0.17.2+rocm5.7, 0.18.0, 0.18.0+cpu, 0.18.0+cu118, 0.18.0+cu121, 0.18.0+rocm5.7, 0.18.0+rocm6.0, 0.18.1, 0.18.1+cpu, 0.18.1+cu118, 0.18.1+cu121, 0.18.1+rocm5.7, 0.18.1+rocm6.0, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1, 0.23.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1+cu116\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423391b0-6d36-4094-ba91-acaf04633754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–°PyTorchç‰ˆæœ¬: 2.3.1+cu121\n",
      "CUDAå¯ç”¨: True\n",
      "GPUæµ‹è¯•: Tesla P100-PCIE-16GB\n",
      "âœ… GPUæ­£å¸¸å·¥ä½œ!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"æ–°PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUæµ‹è¯•: {torch.cuda.get_device_name(0)}\")\n",
    "    # ç®€å•GPUæµ‹è¯•\n",
    "    x = torch.randn(100, 100).cuda()\n",
    "    y = torch.mm(x, x.t())\n",
    "    print(\"âœ… GPUæ­£å¸¸å·¥ä½œ!\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd5e9ca-4c36-49b9-86ed-01705ab25059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchç‰ˆæœ¬: 2.8.0+cu128\n",
      "NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "å°†BERTé›†æˆåˆ°æ‚¨ç°æœ‰çš„è®­ç»ƒä»£ç ä¸­ - ModelScopeç‰ˆæœ¬\n",
    "ä½¿ç”¨ModelScope BERTæ¨¡å‹è¿›è¡Œå¤šæ ‡ç­¾åˆ†ç±»\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"NumPy: {numpy.__version__}\")\n",
    "\n",
    "\n",
    "# å·¥å…·ç±»\n",
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        import time\n",
    "        self.time = time\n",
    "        self.start_time = self.time.time()\n",
    "    def stop(self):\n",
    "        return self.time.time() - self.start_time\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"æ£€æµ‹å¯ç”¨GPU\"\"\"\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ============ ModelScope BERTæ¨¡å‹ ============\n",
    "# æ¨¡å‹å®šä¹‰\n",
    "class BERTSentimentClassifier(nn.Module):\n",
    "    def __init__(self, model_name='AI-ModelScope/distilbert-base-uncased', num_classes=6, dropout=0.1):\n",
    "        super(BERTSentimentClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        print(f\"âœ… åŠ è½½æ¨¡å‹: {model_name}\")\n",
    "        # å†»ç»“ç­–ç•¥\n",
    "        for param in self.bert.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        if hasattr(self.bert, 'transformer'):\n",
    "            for layer in self.bert.transformer.layer[:-1]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        return self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "# ============ ä¿®æ”¹åçš„è®­ç»ƒå‡½æ•° ============\n",
    "def train_bert_epoch(net, train_iter, loss, updater, device):\n",
    "    \"\"\"\n",
    "    å•ä¸ªepochè®­ç»ƒ - æ·»åŠ æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    metric = Accumulator(3)  # è®­ç»ƒæŸå¤±æ€»å’Œ, å‡†ç¡®æ•°, æ ·æœ¬æ•°\n",
    "\n",
    "    # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    for _, batch in enumerate(train_iter):\n",
    "        # è§£æbatch\n",
    "        if len(batch) == 3:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "        else:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_hat = net(input_ids, attention_mask)\n",
    "                l = loss(y_hat, labels)\n",
    "        else:\n",
    "            y_hat = net(input_ids, attention_mask)\n",
    "            l = loss(y_hat, labels)\n",
    "\n",
    "        # åå‘ä¼ æ’­\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            if scaler is not None:\n",
    "                scaler.scale(l.sum()).backward()\n",
    "                scaler.unscale_(updater)\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "                scaler.step(updater)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                l.sum().backward()\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "                updater.step()\n",
    "\n",
    "        # ç»Ÿè®¡\n",
    "        with torch.no_grad():\n",
    "            acc = multilabel_accuracy(y_hat, labels)\n",
    "            metric.add(l.sum(), acc * labels.shape[0], labels.shape[0])\n",
    "\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "\n",
    "# è®­ç»ƒå‡½æ•°\n",
    "def multilabel_accuracy(y_hat, y):\n",
    "    predictions = torch.sigmoid(y_hat) > 0.5\n",
    "    y = y.bool()\n",
    "    label_wise_acc = (predictions == y).float().mean()\n",
    "    return label_wise_acc.item()\n",
    "def train_bert_epoch(net, train_iter, loss, updater, device):\n",
    "    net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for _, batch in enumerate(train_iter):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat = net(input_ids, attention_mask)\n",
    "        l = loss(y_hat, labels)\n",
    "        updater.zero_grad()\n",
    "        l.sum().backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(),max_norm=1.0)\n",
    "        updater.step()\n",
    "        with torch.no_grad():\n",
    "            acc = multilabel_accuracy(y_hat, labels)\n",
    "            metric.add(l.sum(), acc * labels.shape[0],labels.shape[0])\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def evaluate_bert_accuracy(net, data_iter, device):\n",
    "    net.eval()\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            y_hat = net(input_ids, attention_mask)\n",
    "            acc = multilabel_accuracy(y_hat, labels)\n",
    "            metric.add(acc * labels.shape[0], labels.shape[0])\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_bert_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices, scheduler=None):\n",
    "    \"\"\"\n",
    "    å®Œæ•´è®­ç»ƒæµç¨‹\n",
    "    \"\"\"\n",
    "    print('training on', devices)\n",
    "\n",
    "    if isinstance(devices, list) and len(devices) > 1:\n",
    "        # å¤šGPU\n",
    "        net = nn.DataParallel(net, device_ids=devices)\n",
    "\n",
    "    device = devices[0] if isinstance(devices, list) else devices\n",
    "    net = net.to(device)\n",
    "\n",
    "    timer = Timer()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # è®­ç»ƒ\n",
    "        train_loss, train_acc = train_bert_epoch(\n",
    "            net, train_iter, loss, trainer, device\n",
    "        )\n",
    "\n",
    "        # éªŒè¯\n",
    "        test_acc = evaluate_bert_accuracy(net, test_iter, device)\n",
    "\n",
    "        # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}: '\n",
    "              f'loss {train_loss:.3f}, '\n",
    "              f'train acc {train_acc:.3f}, '\n",
    "              f'test acc {test_acc:.3f}')\n",
    "\n",
    "    print(f'Training completed in {timer.stop():.1f} sec')\n",
    "    print(f'Final: train acc {train_acc:.3f}, test acc {test_acc:.3f}')\n",
    "\n",
    "\n",
    "def read_toxic_comments_real(data_dir, max_samples=None, is_train=True):\n",
    "    \"\"\"\n",
    "    è¯»å–çœŸå®çš„Kaggle Toxic Comment Classificationæ•°æ®\n",
    "    è¿”å›æ ¼å¼: (texts, labels, ids)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if is_train:\n",
    "        csv_path = os.path.join(data_dir, 'train.csv')\n",
    "        print(f\"è¯»å–è®­ç»ƒæ•°æ®: {csv_path}\")\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if max_samples:\n",
    "            df = df.head(max_samples)\n",
    "\n",
    "        texts = df['comment_text'].tolist()\n",
    "        label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        labels = df[label_columns].values.tolist()\n",
    "        ids = df['id'].tolist()\n",
    "\n",
    "        print(f\"åŠ è½½è®­ç»ƒæ•°æ®: {len(texts)} æ¡\")\n",
    "        print(f\"æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(label_columns, df[label_columns].sum().tolist()))}\")\n",
    "\n",
    "        return texts, labels, ids\n",
    "    else:\n",
    "        csv_path = os.path.join(data_dir, 'test.csv')\n",
    "        print(f\"è¯»å–æµ‹è¯•æ•°æ®: {csv_path}\")\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if max_samples:\n",
    "            df = df.head(max_samples)\n",
    "\n",
    "        texts = df['comment_text'].tolist()\n",
    "        ids = df['id'].tolist()\n",
    "\n",
    "        print(f\"åŠ è½½æµ‹è¯•æ•°æ®: {len(texts)} æ¡\")\n",
    "\n",
    "        return texts, None, ids\n",
    "\n",
    "def generate_submission(model, test_loader, device, test_ids, output_path):\n",
    "    \"\"\"\n",
    "    ç”ŸæˆKaggleæäº¤æ–‡ä»¶\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    print(\"ğŸ”® ç”Ÿæˆé¢„æµ‹ç»“æœ...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, _ = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            # è·å–logitså¹¶è½¬æ¢ä¸ºæ¦‚ç‡\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            predictions.extend(probs)\n",
    "\n",
    "    # åˆ›å»ºæäº¤DataFrame\n",
    "    label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        **{col: [pred[i] for pred in predictions] for i, col in enumerate(label_columns)}\n",
    "    })\n",
    "\n",
    "    # ä¿å­˜æäº¤æ–‡ä»¶\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"ğŸ’¾ æäº¤æ–‡ä»¶å·²ä¿å­˜: {output_path}\")\n",
    "    print(f\"ğŸ“Š é¢„æµ‹ç»Ÿè®¡:\")\n",
    "    for i, col in enumerate(label_columns):\n",
    "        avg_prob = sum(pred[i] for pred in predictions) / len(predictions)\n",
    "        print(f\"  {col}: å¹³å‡æ¦‚ç‡ {avg_prob:.4f}\")\n",
    "\n",
    "    return submission_df\n",
    "\n",
    "# æ•°æ®é›†\n",
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        if labels is not None:\n",
    "            self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        else:\n",
    "            self.labels = torch.zeros((len(texts), 6),\n",
    "dtype=torch.float32)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return (\n",
    "            encoding['input_ids'].squeeze(),\n",
    "            encoding['attention_mask'].squeeze(),\n",
    "            self.labels[idx]\n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949ff486-aa79-4983-a257-8980eeecca4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...\n",
      "âœ… è®­ç»ƒæ•°æ®è¯»å–æˆåŠŸ: 10 è¡Œ\n",
      "âœ… æµ‹è¯•æ•°æ®è¯»å–æˆåŠŸ: 10 è¡Œ\n",
      "æ•°æ®åŠ è½½å®Œæˆï¼Œæ²¡æœ‰é—®é¢˜\n"
     ]
    }
   ],
   "source": [
    "  import pandas as pd\n",
    "  import os\n",
    "\n",
    "  print(\"ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...\")\n",
    "  data_dir = 'toxic-comment'\n",
    "\n",
    "  try:\n",
    "      # åªè¯»å–å‡ è¡Œæ•°æ®\n",
    "      train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'),\n",
    "  nrows=10)\n",
    "      print(f\"âœ… è®­ç»ƒæ•°æ®è¯»å–æˆåŠŸ: {len(train_df)} è¡Œ\")\n",
    "\n",
    "      test_df = pd.read_csv(os.path.join(data_dir, 'test.csv'),\n",
    "  nrows=10)\n",
    "      print(f\"âœ… æµ‹è¯•æ•°æ®è¯»å–æˆåŠŸ: {len(test_df)} è¡Œ\")\n",
    "\n",
    "      print(\"æ•°æ®åŠ è½½å®Œæˆï¼Œæ²¡æœ‰é—®é¢˜\")\n",
    "  except Exception as e:\n",
    "      print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1c36f6f-5e4b-4c78-a4d1-0d7bba70f971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/AI-ModelScope/bert-base-uncased\n",
      "âœ… Tokenizeræµ‹è¯•æˆåŠŸ\n",
      "ç¼–ç shape: torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # å…ˆå°è¯•ç®€å•çš„tokenizer\n",
    "    from modelscope import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('AI-ModelScope/bert-base-uncased')\n",
    "    # æµ‹è¯•ç¼–ç \n",
    "    text = \"This is a test\"\n",
    "    encoding = tokenizer(text, max_length=32, truncation=True,\n",
    "padding='max_length', return_tensors='pt')\n",
    "    print(f\"âœ… Tokenizeræµ‹è¯•æˆåŠŸ\")\n",
    "    print(f\"ç¼–ç shape: {encoding['input_ids'].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Tokenizeræµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0ff64f-9e25-4287-b07c-f6d7e0be5a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æµ‹è¯•åŸºç¡€BERTæ¨¡å‹åŠ è½½...\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/AI-ModelScope/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 21:09:24.727865: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-04 21:09:26.352233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BERTæ¨¡å‹åŠ è½½æˆåŠŸ\n",
      "âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: torch.Size([1, 32, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "try:\n",
    "    print(\"ğŸ”„ æµ‹è¯•åŸºç¡€BERTæ¨¡å‹åŠ è½½...\")\n",
    "    from modelscope import AutoModel\n",
    "    # ä½¿ç”¨æœ€ç®€å•çš„BERTæ¨¡å‹\n",
    "    model = AutoModel.from_pretrained('AI-ModelScope/distilbert-base-uncased')\n",
    "    print(f\"âœ… BERTæ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "    # æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "    input_ids = torch.randint(0, 1000, (1, 32))\n",
    "    attention_mask = torch.ones(1, 32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids,\n",
    "attention_mask=attention_mask)\n",
    "    print(f\"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: {outputs.last_hidden_state.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dee6ba28-36d4-497c-b8ad-7573966a2c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æµ‹è¯•å®Œæ•´åˆ†ç±»æ¨¡å‹åˆ›å»º...\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/AI-ModelScope/distilbert-base-uncased\n",
      "âœ… åŠ è½½æ¨¡å‹: AI-ModelScope/distilbert-base-uncased\n",
      "âœ… åˆ†ç±»æ¨¡å‹åˆ›å»ºæˆåŠŸ\n",
      "âœ… åˆ†ç±»æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: torch.Size([2, 6])\n",
      "ğŸ“Š è¾“å‡ºlogitsèŒƒå›´: -0.309 ~ 0.298\n",
      "ğŸ“Š sigmoidæ¦‚ç‡èŒƒå›´: 0.423 ~ 0.574\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"ğŸ”„ æµ‹è¯•å®Œæ•´åˆ†ç±»æ¨¡å‹åˆ›å»º...\")\n",
    "    class BERTSentimentClassifier(nn.Module):\n",
    "        def __init__(self, \n",
    "model_name='AI-ModelScope/distilbert-base-uncased', num_classes=6, \n",
    "dropout=0.1):\n",
    "            super(BERTSentimentClassifier, self).__init__()\n",
    "            from modelscope import AutoModel\n",
    "            self.bert = AutoModel.from_pretrained(model_name)\n",
    "            print(f\"âœ… åŠ è½½æ¨¡å‹: {model_name}\")\n",
    "            # å†»ç»“ç­–ç•¥ - åªè®­ç»ƒæœ€å1å±‚å’Œåˆ†ç±»å™¨\n",
    "            for param in self.bert.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "            # DistilBERTç»“æ„\n",
    "            if hasattr(self.bert, 'transformer'):\n",
    "                for layer in self.bert.transformer.layer[:-1]:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            hidden_size = self.bert.config.hidden_size\n",
    "            self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        def forward(self, input_ids, attention_mask):\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "attention_mask=attention_mask)\n",
    "            pooled_output = outputs.last_hidden_state[:, 0]\n",
    "            return self.classifier(self.dropout(pooled_output))\n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    net = BERTSentimentClassifier(num_classes=6, dropout=0.1)\n",
    "    print(f\"âœ… åˆ†ç±»æ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "    # æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "    input_ids = torch.randint(0, 1000, (2, 32))\n",
    "    attention_mask = torch.ones(2, 32)\n",
    "    with torch.no_grad():\n",
    "        logits = net(input_ids, attention_mask)\n",
    "    print(f\"âœ… åˆ†ç±»æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: {logits.shape}\")\n",
    "    print(f\"ğŸ“Š è¾“å‡ºlogitsèŒƒå›´: {logits.min():.3f} ~ {logits.max():.3f}\")\n",
    "    # æµ‹è¯•sigmoidæ¦‚ç‡\n",
    "    probs = torch.sigmoid(logits)\n",
    "    print(f\"ğŸ“Š sigmoidæ¦‚ç‡èŒƒå›´: {probs.min():.3f} ~ {probs.max():.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dffdf39b-f6e2-4766-be64-bf55b416ce2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æµ‹è¯•è®­ç»ƒå¾ªç¯ç»„ä»¶...\n",
      "ğŸ“Š æ¨¡æ‹Ÿæ•°æ®:\n",
      "  logits shape: torch.Size([2, 6])\n",
      "  labels shape: torch.Size([2, 6])\n",
      "  labels ç¤ºä¾‹: tensor([0., 0., 0., 0., 0., 0.])\n",
      "âœ… æŸå¤±è®¡ç®—æˆåŠŸ: torch.Size([2, 6]), å¹³å‡æŸå¤±: 0.9190\n",
      "âœ… å‡†ç¡®ç‡è®¡ç®—æˆåŠŸ: 0.3333\n",
      "âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ\n",
      "âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸ, æŸå¤±: 0.6747\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"ğŸ”„ æµ‹è¯•è®­ç»ƒå¾ªç¯ç»„ä»¶...\")\n",
    "    from torch.optim import AdamW\n",
    "    # æµ‹è¯•æŸå¤±å‡½æ•°\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\n",
    "    batch_size = 2\n",
    "    num_classes = 6\n",
    "    logits = torch.randn(batch_size, num_classes)\n",
    "    labels = torch.randint(0, 2, (batch_size, num_classes)).float()\n",
    "    print(f\"ğŸ“Š æ¨¡æ‹Ÿæ•°æ®:\")\n",
    "    print(f\"  logits shape: {logits.shape}\")\n",
    "    print(f\"  labels shape: {labels.shape}\")\n",
    "    print(f\"  labels ç¤ºä¾‹: {labels[0]}\")\n",
    "    # æµ‹è¯•æŸå¤±è®¡ç®—\n",
    "    loss = loss_fn(logits, labels)\n",
    "    print(f\"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {loss.shape}, å¹³å‡æŸå¤±: {loss.mean():.4f}\")\n",
    "    # æµ‹è¯•å‡†ç¡®ç‡è®¡ç®—\n",
    "    def multilabel_accuracy(y_hat, y):\n",
    "        predictions = torch.sigmoid(y_hat) > 0.5\n",
    "        y = y.bool()\n",
    "        label_wise_acc = (predictions == y).float().mean()\n",
    "        return label_wise_acc.item()\n",
    "    acc = multilabel_accuracy(logits, labels)\n",
    "    print(f\"âœ… å‡†ç¡®ç‡è®¡ç®—æˆåŠŸ: {acc:.4f}\")\n",
    "    # æµ‹è¯•ä¼˜åŒ–å™¨\n",
    "    optimizer = AdamW([\n",
    "        {'params': net.classifier.parameters(), 'lr': 1e-3},\n",
    "        {'params': [p for p in net.bert.parameters() if p.requires_grad], 'lr': 1e-4}\n",
    "    ], weight_decay=0.01)\n",
    "    print(f\"âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ\")\n",
    "    # æµ‹è¯•ä¸€æ­¥è®­ç»ƒ\n",
    "    optimizer.zero_grad()\n",
    "    logits = net(input_ids, attention_mask)\n",
    "    loss = loss_fn(logits, labels).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸ, æŸå¤±: {loss.item():.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è®­ç»ƒå¾ªç¯æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebb8cb-8423-4d08-bb4a-be538679bd60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¯åŠ¨ModelScope BERTå¤šæ ‡ç­¾åˆ†ç±»è®­ç»ƒ\n",
      "ğŸ“Š åŠ è½½çœŸå®Kaggleæ•°æ®...\n",
      "è¯»å–è®­ç»ƒæ•°æ®: toxic-comment/train.csv\n",
      "åŠ è½½è®­ç»ƒæ•°æ®: 1000 æ¡\n",
      "æ ‡ç­¾åˆ†å¸ƒ: {'toxic': 105, 'severe_toxic': 9, 'obscene': 49, 'threat': 4, 'insult': 54, 'identity_hate': 9}\n",
      "è¯»å–æµ‹è¯•æ•°æ®: toxic-comment/test.csv\n",
      "åŠ è½½æµ‹è¯•æ•°æ®: 1000 æ¡\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/AI-ModelScope/bert-base-uncased\n",
      "\n",
      "ğŸ“Š æ•°æ®ç»Ÿè®¡:\n",
      "è®­ç»ƒæ•°æ®: 800 æ¡\n",
      "éªŒè¯æ•°æ®: 200 æ¡\n",
      "æµ‹è¯•æ•°æ®: 1000 æ¡\n",
      "\n",
      "ğŸ“ æ•°æ®æ ·ä¾‹:\n",
      "æ–‡æœ¬é•¿åº¦: 264\n",
      "å‰100å­—ç¬¦: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't \n",
      "æ ‡ç­¾: [0, 0, 0, 0, 0, 0]\n",
      "\n",
      "ğŸ”§ Tokenizeræµ‹è¯•:\n",
      "input_ids shape: torch.Size([1, 128])\n",
      "attention_mask shape: torch.Size([1, 128])\n",
      "å®é™…tokenæ•°: 68\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/hub/models/AI-ModelScope/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 21:32:58.257984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-04 21:32:59.915545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŠ è½½æ¨¡å‹: AI-ModelScope/distilbert-base-uncased\n",
      "ğŸ”¥ ä½¿ç”¨è®¾å¤‡: cuda\n",
      "training on cuda\n"
     ]
    }
   ],
   "source": [
    "# ============ ä¸»è¦æ‰§è¡Œä»£ç  ============\n",
    "print(\"ğŸš€ å¯åŠ¨ModelScope BERTå¤šæ ‡ç­¾åˆ†ç±»è®­ç»ƒ\")\n",
    "# æ•°æ®ç›®å½•\n",
    "data_dir = 'toxic-comment'\n",
    "# æ•°æ®åŠ è½½\n",
    "print(\"ğŸ“Š åŠ è½½çœŸå®Kaggleæ•°æ®...\")\n",
    "# ä¸ºäº†å¿«é€Ÿè®­ç»ƒï¼Œé™åˆ¶æ ·æœ¬æ•°ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰\n",
    "train_texts, train_labels, train_ids = read_toxic_comments_real(\n",
    "    data_dir, max_samples=1000, is_train=True\n",
    ")\n",
    "# åˆ›å»ºéªŒè¯é›†ï¼ˆä»è®­ç»ƒæ•°æ®ä¸­åˆ†å‰²ï¼‰\n",
    "val_split = int(len(train_texts) * 0.8)\n",
    "val_texts = train_texts[val_split:]\n",
    "val_labels = train_labels[val_split:]\n",
    "train_texts = train_texts[:val_split]\n",
    "train_labels = train_labels[:val_split]\n",
    "# è¯»å–æµ‹è¯•æ•°æ®\n",
    "test_texts, _, test_ids = read_toxic_comments_real(\n",
    "    data_dir, max_samples=1000, is_train=False\n",
    ")\n",
    "# åˆå§‹åŒ–tokenizer - ä½¿ç”¨æŒ‡å®šçš„ModelScope BERTæ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained('AI-ModelScope/bert-base-uncased')\n",
    "print(f\"\\nğŸ“Š æ•°æ®ç»Ÿè®¡:\")\n",
    "print(f\"è®­ç»ƒæ•°æ®: {len(train_texts)} æ¡\")\n",
    "print(f\"éªŒè¯æ•°æ®: {len(val_texts)} æ¡\")\n",
    "print(f\"æµ‹è¯•æ•°æ®: {len(test_texts)} æ¡\")\n",
    "# æ£€æŸ¥æ•°æ®è´¨é‡\n",
    "print(f\"\\nğŸ“ æ•°æ®æ ·ä¾‹:\")\n",
    "print(f\"æ–‡æœ¬é•¿åº¦: {len(train_texts[0])}\")\n",
    "print(f\"å‰100å­—ç¬¦: {train_texts[0][:100]}\")\n",
    "print(f\"æ ‡ç­¾: {train_labels[0]}\")\n",
    "# æ£€æŸ¥tokenizer\n",
    "sample_encoding = tokenizer(train_texts[0], max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
    "print(f\"\\nğŸ”§ Tokenizeræµ‹è¯•:\")\n",
    "print(f\"input_ids shape: {sample_encoding['input_ids'].shape}\")\n",
    "print(f\"attention_mask shape: {sample_encoding['attention_mask'].shape}\")\n",
    "print(f\"å®é™…tokenæ•°: {sample_encoding['attention_mask'].sum()}\")\n",
    "# æ¨¡å‹å‚æ•°\n",
    "num_classes = 6  # 6ä¸ªç±»åˆ«ï¼štoxic, severe_toxic, obscene, threat, insult, identity_hate\n",
    "dropout = 0.1\n",
    "batch_size = 16  # é€‚é…åœ¨çº¿ç¯å¢ƒ\n",
    "num_steps = 32  # åºåˆ—é•¿åº¦\n",
    "lr = 1e-4  # å­¦ä¹ ç‡\n",
    "num_epochs = 3  # å¢åŠ åˆ°3ä¸ªepochè·å¾—æ›´å¥½æ•ˆæœ\n",
    " # ä½¿ç”¨ModelScopeä¸Šå®é™…å­˜åœ¨çš„BERTæ¨¡å‹\n",
    "model_name = 'AI-ModelScope/distilbert-base-uncased'\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "net = BERTSentimentClassifier(\n",
    "    model_name=model_name,\n",
    "    num_classes=num_classes,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "train_dataset = BERTDataset(train_texts, train_labels, tokenizer, max_length=num_steps)\n",
    "val_dataset = BERTDataset(val_texts, val_labels, tokenizer, max_length=num_steps)\n",
    "test_dataset = BERTDataset(test_texts, None, tokenizer, max_length=num_steps)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers=0, pin_memory=False)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                       num_workers=0, pin_memory=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                        num_workers=0, pin_memory=False)\n",
    "# ä¼˜åŒ–å™¨ - åªè®­ç»ƒæœ€åä¸€å±‚å’Œåˆ†ç±»å™¨\n",
    "trainer = AdamW([\n",
    "    {'params': [p for name, p in net.named_parameters() if 'classifier' in name], 'lr': lr * 10},  # åˆ†ç±»å±‚\n",
    "    {'params': [p for name, p in net.named_parameters() if 'classifier' not in name and p.requires_grad], 'lr': lr}  # BERTå±‚\n",
    "], weight_decay=0.01)\n",
    "# æŸå¤±å‡½æ•° - å¤šæ ‡ç­¾åˆ†ç±»ä½¿ç”¨BCEWithLogitsLoss\n",
    "loss = nn.BCEWithLogitsLoss(reduction=\"none\")  # æ¯ä¸ªæ ·æœ¬æ¯ä¸ªæ ‡ç­¾ç‹¬ç«‹è®¡ç®—\n",
    "# è®­ç»ƒ\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "train_bert_ch13(net, train_iter, val_iter, loss, trainer, num_epochs, device, None)\n",
    "# ç”Ÿæˆæäº¤æ–‡ä»¶\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¤ ç”ŸæˆKaggleæäº¤æ–‡ä»¶...\")\n",
    "print(\"=\"*60)\n",
    "submission_path = 'toxic_comment/submission.csv'\n",
    "submission_df = generate_submission(net, test_iter, device, test_ids, submission_path)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ModelScope BERTè®­ç»ƒå’Œé¢„æµ‹å®Œæˆ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… æ¨¡å‹:{model_name}\")\n",
    "print(f\"âœ… è®­ç»ƒæ ·æœ¬: {len(train_texts)}\")\n",
    "print(f\"âœ… éªŒè¯æ ·æœ¬: {len(val_texts)}\")\n",
    "print(f\"âœ… æµ‹è¯•æ ·æœ¬: {len(test_texts)}\")\n",
    "print(f\"âœ… æäº¤æ–‡ä»¶: {submission_path}\")\n",
    "print(\"âœ… æ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»\")\n",
    "print(\"âœ… æ··åˆç²¾åº¦è®­ç»ƒ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7095947c-6091-4e21-b3c8-d7de82ec18bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
